{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSP_Final_Code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muazzam9/HelloWorld/blob/master/DSP_Final_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u4CIUapMEiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa\n",
        "import math\n",
        "import pandas as pd\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "from sklearn.datasets import make_classification \n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.io import wavfile\n",
        "import scipy as sp\n",
        "import scipy.fftpack\n",
        "import random\n",
        "import wave, os, glob\n",
        "from scipy.signal import hilbert, chirp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "from scipy.signal import find_peaks\n",
        "import ntpath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwEGYXmPNmjb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad3a5e81-689d-4d65-c99e-83427aee21c6"
      },
      "source": [
        "pip install pydub "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.6/dist-packages (0.24.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bqgH4STNr1-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f31c6288-12d7-49b8-de62-2d00b8b681f6"
      },
      "source": [
        "pip install pysoundfile "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pysoundfile in /usr/local/lib/python3.6/dist-packages (0.9.0.post1)\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.6/dist-packages (from pysoundfile) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=0.6->pysoundfile) (2.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_O5bsRCPN7Cn",
        "colab_type": "text"
      },
      "source": [
        "# Read File Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE6m2BPKN-q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Read_Audio_Folder(r_folder_path):#folder path must be in raw string format\n",
        "    audiodata = []\n",
        "    audiosr = []\n",
        "    files_paths= []\n",
        "    for filename in glob.glob(os.path.join(r_folder_path,'*.wav')):\n",
        "        \n",
        "        files_paths.append(filename)\n",
        "   \n",
        "    files_paths = sorted(files_paths)#changed from str.lower\n",
        "    return files_paths\n",
        "# file_name = os.path.join(os.path.abspath('/UrbanSound8K/audio/'),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
        "\n",
        "def file_name_finder(files_paths):#takes in a folder path and returns a list of the file names \n",
        "  file_names = []\n",
        "  for i in range (len(files_paths)):#loops through array of file paths\n",
        "    name = path_leaf(files_paths[i])\n",
        "    file_names.append(name)\n",
        "  return file_names#returns file names in the same order as the file paths with the extension\n",
        "\n",
        "  import ntpath\n",
        "def path_leaf(path):#function to rextract file name from a file path with the extension type or file type\n",
        "    head, tail = ntpath.split(path)#splits the path based on the \\ delimiter \n",
        "    return tail or ntpath.basename(head) #returns the filename with the extension\n",
        "\n",
        "def key_name(file_names):\n",
        "  key_names = []\n",
        "  for i in range(len(file_names)):\n",
        "    key = file_names[i].split('_',1)\n",
        "    key_names.append(key[0])\n",
        "  return key_names #returns an array of the key names\n",
        "\n",
        "from statistics import mode\n",
        "def dict_maker(mod_freq):\n",
        "  keys = {}\n",
        "  for i in range(0,len(mod_freq)):\n",
        "    key = str(mod_freq[i][0])\n",
        "    value = mod_freq[i][1]\n",
        "    keys.update({key:value})\n",
        "  return keys\n",
        "\n",
        "def n_conv(arr):\n",
        "  new_arr = []\n",
        "  for i in arr:\n",
        "    if i == 1:\n",
        "      new_arr.append(\"A#5\") \n",
        "    elif i == 2:\n",
        "      new_arr.append(\"A5\")\n",
        "    elif i == 3:\n",
        "      new_arr.append(\"B5\")\n",
        "    elif i == 4:\n",
        "      new_arr.append(\"C#4\")\n",
        "    elif i == 5:\n",
        "      new_arr.append(\"C4\")\n",
        "    elif i == 6:\n",
        "      new_arr.append(\"C5\")\n",
        "    elif i == 7:\n",
        "      new_arr.append(\"D#4\")  \n",
        "    elif i == 8:\n",
        "      new_arr.append(\"D4\")\n",
        "    elif i == 9:\n",
        "      new_arr.append(\"E4\")\n",
        "    elif i == 10:\n",
        "      new_arr.append(\"F#4\")\n",
        "    elif i == 11:\n",
        "      new_arr.append(\"F4\")\n",
        "    elif i == 12:\n",
        "      new_arr.append(\"G#4\")\n",
        "    elif i == 13:\n",
        "      new_arr.append(\"G4\")  \n",
        "  return new_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKJgNpfXOCCq",
        "colab_type": "text"
      },
      "source": [
        "Machine Learning Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YS-gAGtOMaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def features(x,i):\n",
        "  data, fs = librosa.load(x[i],sr=None, mono=True)\n",
        "  fft = sp.fftpack.fft(data)\n",
        "  sample_freq = sp.fftpack.fftfreq(data.size, d=1/fs)\n",
        "  indices = (np.argsort(abs(fft))) #indices in ascending order of amplitudes\n",
        "  reverse = indices[::-1] #indices in  decending order of amplitudes\n",
        "  max_indices = reverse[0] #array of indicies relating to max amplitudes\n",
        "  \n",
        "  feature_list = (abs(sample_freq[max_indices]))\n",
        "  return feature_list\n",
        "\n",
        "def train(folder_path):\n",
        "  y_train = []\n",
        "  x_train = []\n",
        "  x_train_file = []\n",
        "  files_paths1 = Read_Audio_Folder('/content/drive/My Drive/Colab Notebooks/Audio')\n",
        "  files_names1 = file_name_finder(files_paths1)\n",
        "  a = 1\n",
        "  j = 0 \n",
        "\n",
        "  for i in range(130):\n",
        "    x_train.append([features(files_paths1, i),i])\n",
        "    x_train_file.append([features(files_paths1, i), files_names1[i]])\n",
        " \n",
        "    if j == 10:\n",
        "      j=0\n",
        "      a=a+1 \n",
        "    y_train.append(a)\n",
        "    j=j+1\n",
        "  return x_train, y_train, x_train_file\n",
        "\n",
        "from statistics import mode\n",
        "from collections import Counter\n",
        "def mode_frequency(xtrainfile, keynames):\n",
        "  mode_freq = []\n",
        "  rxtrainfile = []\n",
        "  for j in range(0,len(xtrainfile)):\n",
        "    rounded_value = round(xtrainfile[j][0])\n",
        "    rxtrainfile.append(rounded_value)\n",
        "  for i in range(0,len(rxtrainfile),10):\n",
        "    c = Counter(rxtrainfile[i:i+10])\n",
        "    mod = np.asarray(c.most_common(1))\n",
        "    mode_freq.append([keynames[i],mod[0][0]])\n",
        "  return mode_freq\n",
        "\n",
        "def calculateDistances(x_test, X_in):  \n",
        "    distance_list = []\n",
        "    for x in range(len(X_in)):\n",
        "        distance_list.append(abs(x_test - X_in[x]))\n",
        "    \n",
        "    return distance_list\n",
        "\n",
        "def kNearestIndices(distance_list, k):\n",
        "    k_nearest_indices = (np.argsort(distance_list))[0:k]\n",
        "    #print(type(k_nearest_indices))\n",
        "    \n",
        "    return k_nearest_indices\n",
        "\n",
        "def kNearestNeighbours(k_nearest_indices, X_in, Y_in):\n",
        "\n",
        "  \"\"\"  X_k = (X_in[k_nearest_indices]) \n",
        "    Y_k = (Y_in[k_nearest_indices])\n",
        "    D_k = (X_k,Y_k)\n",
        "    #print(X_k.shape)\n",
        "    return (X_k,Y_k)\"\"\"\n",
        "  Y_k=[]\n",
        "  X_k=[]\n",
        "  for i in k_nearest_indices:{\n",
        "      X_k.append(X_in[i]),Y_k.append(Y_in[i])\n",
        "    }\n",
        "  return X_k, Y_k\n",
        "\n",
        "from scipy.stats import mode\n",
        "def predict(x_test, X_in, Y_in, k):\n",
        "\n",
        "    D_k = (kNearestNeighbours(kNearestIndices(calculateDistances(x_test, X_in), k), X_in, Y_in))\n",
        "    prediction= mode(D_k[1])[0][0]\n",
        "    #print(D_k[0])\n",
        "    #print(D_k[1])\n",
        "    return prediction\n",
        "\n",
        "def predictBatch(X_t, X_in, Y_in, k):\n",
        "    \n",
        "    Y_k = []\n",
        "    for i in X_t:\n",
        "        Y_k.append((kNearestNeighbours(kNearestIndices(calculateDistances(i, X_in), k), X_in, Y_in))[1]) #dont need    \n",
        "    #print(Y_k)\n",
        "    #print(type(kNearestNeighbours(kNearestIndices(calculateDistances(i, X_in), k), X_in, Y_in)[1]))\n",
        "    predictionslist=[]\n",
        "    for a in Y_k:\n",
        "        predictionslist.append(mode(a)[0][0])\n",
        "        predictions = np.asarray(predictionslist)\n",
        "    #print(type(predictions))\n",
        "    #print(predictions.shape)\n",
        "    return predictions\n",
        "\n",
        "def accuracy(Y_pred, Y_test):\n",
        "   \n",
        "    count = 0\n",
        "    for i in range(len(Y_test)):\n",
        "        if Y_pred[i]==Y_test[i]:\n",
        "            count = count+1\n",
        "        else:\n",
        "            count = count\n",
        "    accuracy = count/len(Y_pred)\n",
        "    \n",
        "    return accuracy\n",
        "\n",
        "def run(X_train, X_test, Y_train, Y_test, k):\n",
        "\n",
        "    test_accuracy = accuracy(predictBatch(X_test, X_train, Y_train, k), Y_test)\n",
        "    #print(predictBatch(X_test, X_train, Y_train, k))\n",
        "    return test_accuracy\n",
        "\n",
        "def createTrain(folder_path,no_samples_train):\n",
        "  y_train = []\n",
        "  x_train = []\n",
        "  x_train_file = []\n",
        "  files_paths1 = Read_Audio_Folder(folder_path)\n",
        "  files_names1 = file_name_finder(files_paths1)\n",
        "  a = 1\n",
        "  j = 0 \n",
        "\n",
        "  for i in range(len(files_paths1)):\n",
        "    x_train.append(features(files_paths1,i))\n",
        "    x_train_file.append([features(files_paths1, i), files_names1[i]])\n",
        " \n",
        "    if j == no_samples_train:\n",
        "      j=0\n",
        "      a=a+1 \n",
        "    y_train.append(a)\n",
        "    j=j+1\n",
        "  return x_train, y_train, x_train_file\n",
        "\n",
        "def createTest(folder_path, no_tests_per_sample):\n",
        "  y_test = []\n",
        "  x_test = []\n",
        "  x_test_file = []\n",
        "  files_paths1 = Read_Audio_Folder(folder_path)\n",
        "  files_names1 = file_name_finder(files_paths1)\n",
        "  a = 1\n",
        "  j = 0 \n",
        "\n",
        "  for i in range(len(files_paths1)):\n",
        "    x_test.append(features(files_paths1,i))\n",
        "    x_test_file.append([features(files_paths1, i), files_names1[i]])\n",
        " \n",
        "    if j == no_tests_per_sample:\n",
        "      j=0\n",
        "      a=a+1 \n",
        "    y_test.append(a)\n",
        "    j=j+1\n",
        "  return x_test, x_test_file\n",
        "\n",
        "def  data_list(audio_path):\n",
        "  data_list1 = []\n",
        "  data_ave = []\n",
        "  a = 0\n",
        "  data, fs = librosa.load(audio_path,sr=None)\n",
        "  for i in data:\n",
        "    data_list1.append(i)\n",
        "  return(data_list1)\n",
        "\n",
        "def  aveSig(audio_path,ave_amount):\n",
        "  data_list = []\n",
        "  data_ave = []\n",
        "  a = 0\n",
        "  data, fs = librosa.load(audio_path,sr=None)\n",
        "  for i in data:\n",
        "    data_list.append(i)\n",
        "  while a < len(data_list):\n",
        "    data_ave.append(sum(data_list[a:a + ave_amount])/ave_amount) \n",
        "    a = a + ave_amount\n",
        "  print(len(data_list))\n",
        "  print(len(data_ave))\n",
        "  return(data_ave)\n",
        "\n",
        "def thresh(data_ave, threshold, lowerlimit):\n",
        "  thresh_data = []\n",
        "  for i in range(len(data_ave)):\n",
        "    if abs(data_ave[i]) >= threshold:\n",
        "      thresh_data.append(data_ave[i])\n",
        "    else:\n",
        "      thresh_data.append(lowerlimit) \n",
        "  return(thresh_data)\n",
        "\n",
        "def divide_chunks(list, size_chunk): \n",
        "    for i in range(0, len(list), size_chunk):  \n",
        "        yield list[i:i + size_chunk] \n",
        "\n",
        "def LLToLNP(listlist):\n",
        "  segment_arr = []\n",
        "  for i in listlist:\n",
        "    segment_arr.append(np.asarray(i))\n",
        "  return(segment_arr)\n",
        "\n",
        "def featuresForData(listOfArrays,minfreq,ave_amount):\n",
        "  feature_list = []\n",
        "  for x in listOfArrays:\n",
        "    fft = sp.fftpack.fft(x)\n",
        "    sample_freq = sp.fftpack.fftfreq(x.size, d=1/(44100/ave_amount))\n",
        "    indices = (np.argsort(abs(fft))) #indices in ascending order of amplitudes\n",
        "    reverse = indices[::-1] #indices in  decending order of amplitudes\n",
        "    max_indices = reverse[0] #array of indicies relating to max amplitudes\n",
        "    feature_list.append(abs(sample_freq[max_indices]))\n",
        "\n",
        "  feature_list_reduced = []\n",
        "  for z in feature_list:\n",
        "    if z >= minfreq:\n",
        "      feature_list_reduced.append(z)\n",
        "  return(feature_list_reduced)\n",
        "\n",
        "import math\n",
        "def roundup10(f_list):\n",
        "  feature_round = []\n",
        "  for x in f_list:\n",
        "    feature_round.append(roundup(x))\n",
        "  return int(math.ceil(x / 10.0)) * 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey87qSiyOQ-2",
        "colab_type": "text"
      },
      "source": [
        "# DSP Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gOXstLuOT1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "def chunk(song,silence_length,threshdB):\n",
        "  chunks = split_on_silence (song, min_silence_len = silence_length,silence_thresh = threshdB,keep_silence=80)\n",
        "  return(chunks)\n",
        "\n",
        "def frequencies(chunks):\n",
        "  frequency_list = []\n",
        "  for i in chunks:\n",
        "    wav_file = i\n",
        "    samples = wav_file.get_array_of_samples()#gets the values instead of objects\n",
        "    npsample = np.asarray(samples)\n",
        "    fft = sp.fftpack.fft(npsample)\n",
        "    sample_freq = sp.fftpack.fftfreq(npsample.size, d=1/(44100))\n",
        "    indices = (np.argsort(abs(fft))) #indices in ascending order of amplitudes\n",
        "    reverse = indices[::-1] #indices in  decending order of amplitudes\n",
        "    max_indices = reverse[0] #array of indicies relating to max amplitudes\n",
        "    frequency_list.append(abs(sample_freq[max_indices]))\n",
        "  return(frequency_list)\n",
        "\n",
        "def find_silence_length(song,thresh_dB,no_of_notes):#determines minimum silence length\n",
        "  length = 0\n",
        "  for i in range(200):#found that recommended silence ength is between 1 and 200ms\n",
        "    chunks = chunk(song,i,thresh_dB)#chunks the data\n",
        "    if(len(frequencies(chunks)) == no_of_notes):#checks if the number of frequencies found equals no. of notes\n",
        "      length=i\n",
        "      break\n",
        "  return length#returns the silence length\n",
        "\n",
        "def no_of_notes(data,fs,threshold):\n",
        "  #data as a numpy array\n",
        "  max_indexes = []\n",
        "  sample_removal = int(round(0.2*fs))\n",
        "  while ((data[int(np.argmax(data))])>threshold):\n",
        "    current_max = int(np.argmax(data))\n",
        "    max_indexes.append(current_max)\n",
        "    for i in range(current_max-sample_removal,(current_max+(sample_removal+1))):\n",
        "      data[i]=0\n",
        "  maxes = np.asarray(max_indexes)\n",
        "  return maxes, data\n",
        "#staccato length = 0.812s to 0.963s = 0.15s this is the assumed minimum duration of a key press\n",
        "#set the minimum peak to be 0.1\n",
        "\n",
        "def find_first_index(envelope):\n",
        "  for i in range(envelope.size):\n",
        "    if envelope[i]>0.4:\n",
        "      return i\n",
        "      exit\n",
        "    else:\n",
        "      exit\n",
        "\n",
        "def last_index_finder(start_index,envelope):\n",
        "  for i in range(start_index,envelope.size):\n",
        "    if envelope[i]<0.4:\n",
        "      return i-1\n",
        "      exit\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "def bpm_converter(bpm,fs):#function that takes in beats per minute\n",
        "  bps = bpm/60 #converts beats per minute to beats per second\n",
        "  beat_duration = (1/bps)*fs #the number of samples the beat would take up \n",
        "  return beat_duration\n",
        "\n",
        "def squareSig(audio_file, threshold):\n",
        "  data_pm, fs_pm = librosa.load(audio_file,sr=None)\n",
        "  max1 = np.argmax(data_pm)\n",
        "  scale = (0.8/data_pm[max1])\n",
        "  data_pm = data_pm * scale\n",
        "  split_list = []\n",
        "  for i in range(len(data_pm)):\n",
        "    if abs(data_pm[i]) >= threshold:\n",
        "      split_list.append(data_pm[i])\n",
        "    else:\n",
        "      split_list.append(0) \n",
        "  slist = np.asarray(split_list)\n",
        "\n",
        "  analytic_signal = hilbert(slist)\n",
        "  amplitude_envelope = np.abs(analytic_signal)\n",
        "  start_index = find_first_index(amplitude_envelope)\n",
        "  end_index = last_index_finder(start_index,amplitude_envelope)\n",
        "  arr = []\n",
        "  for i in range(amplitude_envelope.size):\n",
        "    if abs(amplitude_envelope[i])>threshold:\n",
        "      arr.append(1.0)\n",
        "    else: \n",
        "      arr.append(0)\n",
        "  square_wave = np.asarray(arr)\n",
        "  return(square_wave, data_pm, fs_pm)\n",
        "\n",
        "def squareSig2(audio_file, threshold):\n",
        "  song = AudioSegment.from_wav(audio_file)\n",
        "\n",
        "  song = song.high_pass_filter(250)\n",
        "\n",
        "  samples = song.get_array_of_samples()#gets the values instead of objects\n",
        "  npsample = np.asarray(samples)\n",
        "  data_pm = npsample\n",
        "  fs_pm = 44100\n",
        "  max1 = np.argmax(data_pm)\n",
        "  scale = (0.8/data_pm[max1])\n",
        "  data_pm = data_pm * scale\n",
        "  split_list = []\n",
        "  for i in range(len(data_pm)):\n",
        "    if abs(data_pm[i]) >= threshold:\n",
        "      split_list.append(data_pm[i])\n",
        "    else:\n",
        "      split_list.append(0) \n",
        "  slist = np.asarray(split_list)\n",
        "\n",
        "  analytic_signal = hilbert(slist)\n",
        "  amplitude_envelope = np.abs(analytic_signal)\n",
        "  start_index = find_first_index(amplitude_envelope)\n",
        "  end_index = last_index_finder(start_index,amplitude_envelope)\n",
        "  arr = []\n",
        "  for i in range(amplitude_envelope.size):\n",
        "    if abs(amplitude_envelope[i])>threshold:\n",
        "      arr.append(1.0)\n",
        "    else: \n",
        "      arr.append(0)\n",
        "  square_wave = np.asarray(arr)\n",
        "  return(square_wave, data_pm, fs_pm)\n",
        "\n",
        "def ref_square_wave(sq_wave,fs,bpm):\n",
        "  min_duration = int(round(bpm_converter(bpm,fs)))\n",
        "  counter = 0\n",
        "  list_wave = []\n",
        "  for x in sq_wave:\n",
        "    list_wave.append(x)\n",
        "  for i in range(len(list_wave)):\n",
        "    if sq_wave[i]==1:\n",
        "      counter = counter+1\n",
        "      if counter ==1:\n",
        "        for j in range(i+1,i+1+min_duration):\n",
        "          sq_wave[j]=0\n",
        "        counter=0\n",
        "      else:\n",
        "        sq_wave[i]=1\n",
        "    else:\n",
        "      sq_wave[i]=0\n",
        "  return sq_wave\n",
        "\n",
        "def one_counter(refine_wave):\n",
        "  count = 0\n",
        "  for i in refine_wave:\n",
        "    if i==1:\n",
        "      count = count+1\n",
        "    else:\n",
        "      pass \n",
        "  return count\n",
        "\n",
        "def  aveSigArray(array,ave_amount):\n",
        "  data_list = []\n",
        "  data_ave1 = []\n",
        "  a = 0\n",
        "  data = np.asarray(array)\n",
        "  for i in data:\n",
        "    data_list.append(i)\n",
        "  while a < len(data_list):\n",
        "    data_ave1.append(sum(data_list[a:a + ave_amount])/ave_amount) \n",
        "    a = a + ave_amount\n",
        "  return(np.asarray(data_ave1))\n",
        "\n",
        "def silence(peaks,sample,average):\n",
        "  durations=[]\n",
        "  for i in range(len(peaks)-1):\n",
        "    durations.append((peaks[i+1])/(sample/average)-(peaks[i])/(sample/average))\n",
        "  return(durations)\n",
        "def noteDuration(chunks,sample):\n",
        "  duration_note = []\n",
        "  for i in chunks: \n",
        "    samples = i.get_array_of_samples()#gets the values instead of objects\n",
        "    npsample = np.asarray(samples)\n",
        "    duration_note.append((len(npsample))/(sample))\n",
        "  return(duration_note)\n",
        "\n",
        "\n",
        "def enum(Y_test):\n",
        "  for n, i in enumerate(Y_test):\n",
        "    if i == 8:\n",
        "      Y_test[n] = 6\n",
        "  return Y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIl3uW4vbf7F",
        "colab_type": "text"
      },
      "source": [
        "# Scripting Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cinn5vc6bipD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def key_pos(keys,dif,time):#gets the position in array accorind to time and difference between notes.\n",
        "  key_pos=[]\n",
        "  times=[]\n",
        "  val = 0\n",
        "  for i in range(len(dif)):\n",
        "    val = val+ dif[i]\n",
        "    times.append(val)\n",
        "  count=0\n",
        "\n",
        "  b = int(time*2)\n",
        "\n",
        "\n",
        "  for i in range(b+1):\n",
        "    if(count >= len(times)):\n",
        "      key_pos.append([0,0])\n",
        "    elif(float(i/2)==times[count]):\n",
        "      key_pos.append(keys[count])\n",
        "      count+=1\n",
        "    else:\n",
        "      key_pos.append([0,0])\n",
        "  if count < len(keys):\n",
        "    key_pos.append(keys[count])\n",
        "     \n",
        "  return key_pos\n",
        "\n",
        "def make_arr(key,dur): #makes an array of 2 length arrays\n",
        "  arr=[]\n",
        "  for i in range(len(key)):\n",
        "    arr.append([key[i],dur[i]])\n",
        "  return arr\n",
        "\n",
        "\n",
        "def script(key,dif,dur):# main\n",
        "\n",
        "  time = 0\n",
        "  for i in range(len(dif)):        # standardizes the range of  durstions to 0.5 \n",
        "     dif[i] = round(dif[i]*2) / 2\n",
        "     if dif[i]==0:                 \n",
        "       dif[i]=0.5\n",
        "     dur[i] = round(dur[i]*2)/2\n",
        "     if dif[i]==0:\n",
        "       dif[i]=0.5\n",
        "     time += dif[i] \n",
        "  for i in range(len(dur)): # standardizes the range of  durstions to 0.5 \n",
        "     dur[i] = round(dur[i]*2) / 2\n",
        "     if dur[i]==0:\n",
        "      dur[i]=0.5\n",
        "      dur[i] = round(dur[i]*2)/2\n",
        "     if dur[i]==0:\n",
        "      dur[i]=0.5\n",
        "\n",
        "  no_sheets = math.ceil(time/10) #gets no of sheets\n",
        "  key_dur = make_arr(key,dur) #gets 2d array of keys and dur\n",
        "  #print(key_pos(key_dur,dif,time))\n",
        "  position = key_pos(key_dur,dif,time) # gets the positions of spaces  \n",
        "  length = len(position)\n",
        "  count = 0\n",
        "  sheet_count=0\n",
        "  line1=\"___| \"\n",
        "  line2=\"   | \"\n",
        "  new_count=1\n",
        "  print(\"Sheets                            Legend: 0.5s = ”*”, 1s = ”&”, 1.5s = ”$” , 2s = “+” \"+\"\\n\")\n",
        "  for i in range(no_sheets):   # plots the number of sheets required\n",
        "    for q in range(20):\n",
        "\n",
        "      if new_count>=len(position): #checks if there is more notes to add\n",
        "        line1 = line1 + \"{0:>4}\".format(\"_\")\n",
        "        line2 = line2 + \"{0:>4}\".format(\"-\")\n",
        "      elif position[new_count][0]!= 0:              #if not zero add number and duration\n",
        "        line1 = line1 +  \"{0:>4}\".format(n_conv([position[new_count][0]])[0])\n",
        "        if position[new_count][1]== 0.5:\n",
        "          line2 = line2 + \"{0:>4}\".format(\"*\")\n",
        "\n",
        "        elif position[new_count][1] == 1:\n",
        "          line2 = line2 + \"{0:>4}\".format(\"&\")\n",
        "\n",
        "        elif position[new_count][1] == 1.5:          # check the the symbol \n",
        "          line2 = line2 + \"{0:>4}\".format(\"$\")\n",
        "\n",
        "        elif position[new_count][1] == 2:\n",
        "          line2 = line2 + \"{0:>4}\".format(\"+\")\n",
        "        new_count=new_count+1\n",
        "      else:\n",
        "        line1 = line1 + \"{0:>4}\".format(\"_\")\n",
        "        line2 = line2 + \"{0:>4}\".format(\"-\")\n",
        "        new_count = new_count + 1\n",
        "\n",
        "      \n",
        "        \n",
        "    print('{:s}'.format('\\u0332'.join(line1)))\n",
        "    print(\"   |\")\n",
        "    print(line2)\n",
        "    print(\"___|_________________________________________________________________________________\"+\"\\n\"+\"\\n\")\n",
        "    #print(\"____________________________________________________________________________________\")\n",
        "    line1 = \"___| \"\n",
        "    line2 = \"   | \""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkSjlR3BiII_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(audio_path):\n",
        "  square_wave,data_pm,fs_pm = squareSig(audio_path , 0.3)\n",
        "  ave = 3980\n",
        "  data_ave = aveSigArray(square_wave,ave)\n",
        "  peaks2, _ = find_peaks(data_ave, prominence=0.1) \n",
        "  arr_len = len(peaks2)\n",
        "  silences = silence(peaks2,fs_pm,ave)\n",
        "  song = AudioSegment.from_wav(audio_path)\n",
        "  song = song.high_pass_filter(250)\n",
        "  length = find_silence_length(song,-16.6,arr_len)\n",
        "  chunks = chunk(song,length,-16.6)\n",
        "  freq_chunks = frequencies(chunks)\n",
        "  X_test = freq_chunks\n",
        "  predic = predictBatch(X_test, X_train, Y_train, k)\n",
        "  note_durations = noteDuration(chunks,fs_pm)\n",
        "  \n",
        "  return(X_test,predic,note_durations,silences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwV91KUHZQ0K",
        "colab_type": "text"
      },
      "source": [
        "# Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-7f9xfiOY2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, Y_train, X_train_file = createTrain('/content/Audio',10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET8l6maGPIl8",
        "colab_type": "text"
      },
      "source": [
        "# Model Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maeZX6luPMav",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "a2be2bc1-edc3-478a-9ea3-174731ea3edb"
      },
      "source": [
        "#Model\n",
        "#Add folder\n",
        "# Select perisan_market or  ode_joy.wav and set path equal to audi_path below:\n",
        "\n",
        "audio_path = '/content/Single_Note_Songs.zip'\n",
        "\n",
        "# Select Y_test by uncommenting required one for specific song:\n",
        "\n",
        "#Persian Market\n",
        "Y_test = [9,11,9,4,5,5,4,5,4,9,11,11,13,11,9,4,5,5,4,5,4,9,11] \n",
        "\n",
        "#Ode joy\n",
        "#Y_test = [9,9,11,13,13,11,9,8,5,5,8,9,9,8,8,9,9,11,13,13,11,9,8,5,5,8,9,8,5,5,8,8,9,5,8,9,11,9,5,8,9,11,9,8,5,9,9,11,13,13,11,9,8,5,5,8,9,8,5,5] # ode joy \n",
        "\n",
        "#For corrected ode_joy uncomment code Y_test enum(Y_test)below, provided Y_test ode_joy is uncommented:\n",
        "#Y_test = enum(Y_test)\n",
        "\n",
        "k=2\n",
        "X_test,key,dur, dif = model(audio_path)\n",
        "\n",
        "\n",
        "predic = predictBatch(X_test, X_train, Y_train, k)\n",
        "print('k =',k)\n",
        "print(\"\\n Test Batch\\n\",Y_test)\n",
        "print(\"\\n Predicted Batch\\n\",predic)\n",
        "print(\"\\nAccuracy = \",run(X_train, X_test, Y_train, Y_test, k))\n",
        "\n",
        "print(\"\\n\"+\"\\n\")\n",
        "script(key,dif,dur)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k = 2\n",
            "\n",
            " Test Batch\n",
            " [9, 11, 9, 4, 5, 5, 4, 5, 4, 9, 11, 11, 13, 11, 9, 4, 5, 5, 4, 5, 4, 9, 11]\n",
            "\n",
            " Predicted Batch\n",
            " [ 9  9  5  4  5  5  4  5  4  9 11 11 13 11  9  4  5  5  4  5  4  9 11]\n",
            "\n",
            "Accuracy =  0.9130434782608695\n",
            "\n",
            "\n",
            "\n",
            "Sheets                            Legend: 0.5s = ”*”, 1s = ”&”, 1.5s = ”$” , 2s = “+” \n",
            "\n",
            "_̲_̲_̲|̲ ̲ ̲ ̲E̲4̲ ̲ ̲E̲4̲ ̲ ̲ ̲_̲ ̲ ̲C̲4̲ ̲C̲#̲4̲ ̲ ̲ ̲_̲ ̲ ̲ ̲_̲ ̲ ̲C̲4̲ ̲ ̲ ̲_̲ ̲ ̲ ̲_̲ ̲ ̲C̲4̲ ̲C̲#̲4̲ ̲ ̲C̲4̲ ̲C̲#̲4̲ ̲ ̲E̲4̲ ̲ ̲ ̲_̲ ̲ ̲ ̲_̲ ̲ ̲F̲4̲ ̲ ̲ ̲_̲ ̲ ̲ ̲_\n",
            "   |\n",
            "   |    *   *   -   *   *   -   -   *   -   -   *   *   *   *   *   -   -   *   -   -\n",
            "___|_________________________________________________________________________________\n",
            "\n",
            "\n",
            "_̲_̲_̲|̲ ̲ ̲ ̲F̲4̲ ̲ ̲G̲4̲ ̲ ̲F̲4̲ ̲ ̲ ̲_̲ ̲ ̲E̲4̲ ̲C̲#̲4̲ ̲ ̲ ̲_̲ ̲ ̲ ̲_̲ ̲ ̲C̲4̲ ̲ ̲ ̲_̲ ̲ ̲ ̲_̲ ̲ ̲C̲4̲ ̲C̲#̲4̲ ̲ ̲C̲4̲ ̲C̲#̲4̲ ̲ ̲E̲4̲ ̲ ̲F̲4̲ ̲ ̲ ̲_̲ ̲ ̲ ̲_̲ ̲ ̲ ̲_\n",
            "   |\n",
            "   |    *   *   *   -   *   *   -   -   *   -   -   *   *   *   *   *   *   -   -   -\n",
            "___|_________________________________________________________________________________\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}